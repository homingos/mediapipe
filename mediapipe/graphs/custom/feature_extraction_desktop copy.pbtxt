
input_stream: "input_video_gpu"
input_stream: "query_feats"
input_stream: "match_image"
input_stream: "enable_scanning"

output_stream: "output_video"
output_stream: "output_tensor_floats"
output_stream: "rr_index"

max_queue_size: 200
num_threads: 16

node {
  calculator: "GpuBufferToImageFrameCalculator"
  input_stream: "input_video_gpu"
  output_stream: "input_video_cpu"
}

node {
  calculator: "PassThroughCalculator"
  input_stream: "input_video_cpu"
  output_stream: "scanning_frame"
}


node {
  calculator: "StreamToSidePacketCalculator"
  input_stream: "enable_scanning"
  output_side_packet: "enable_scanning_side_packet"
}

node {
  calculator: "SidePacketToStreamCalculator"
  input_stream: "TICK:scanning_frame"
  input_side_packet: "enable_scanning_side_packet"
  output_stream: "AT_TICK:enable_scanning_packet"
}

node {
    calculator: "GateCalculator"
    input_stream: "scanning_frame"
    input_stream: "ALLOW:enable_scanning_packet"
    output_stream: "scanning_frame_enabled"
}

node {
  calculator: "ScanningSubgraph"
  input_stream: "scanning_frame_enabled"
  input_stream: "query_feats"
  output_stream: "FLOATS:output_tensor_floats"
  output_stream: "rr_index"
}

node {
  calculator: "TrackingSubgraph"
  input_stream: "input_video_cpu"
  input_stream: "match_image"
  output_stream: "box_output"
}

node: {
  calculator: "MotionAnalysisCalculator"
  input_stream: "VIDEO:input_video_cpu"
  output_stream: "CAMERA:camera_motion"
  output_stream: "FLOW:region_flow"

  node_options: {
    [type.googleapis.com/mediapipe.MotionAnalysisCalculatorOptions]: {
      analysis_options {
        analysis_policy: ANALYSIS_POLICY_CAMERA_MOBILE
        flow_options {
          fast_estimation_min_block_size: 100
          top_inlier_sets: 1
          frac_inlier_error_threshold: 3e-3
          downsample_mode: DOWNSAMPLE_TO_INPUT_SIZE
          verification_distance: 5.0
          verify_long_feature_acceleration: true
          verify_long_feature_trigger_ratio: 0.1
          tracking_options {
            max_features: 500
            adaptive_extraction_levels: 2
            min_eig_val_settings {
              adaptive_lowest_quality_level: 2e-4
            }
            klt_tracker_implementation: KLT_OPENCV
          }
        }
      }
    }
  }
}

# Reads optical flow fields defined in
# mediapipe/framework/formats/motion/optical_flow_field.h,
# returns a VideoFrame with 2 channels (v_x and v_y), each channel is quantized
# to 0-255.
node: {
  calculator: "FlowPackagerCalculator"
  input_stream: "FLOW:region_flow"
  input_stream: "CAMERA:camera_motion"
  output_stream: "TRACKING:tracking_data"

  node_options: {
    [type.googleapis.com/mediapipe.FlowPackagerCalculatorOptions]: {
      flow_packager_options: {
        binary_tracking_data_support: false
      }
    }
  }
}

# Tracks box positions over time.
node: {
  calculator: "BoxTrackerCalculator"
  input_stream: "TRACKING:tracking_data"
  input_stream: "TRACK_TIME:input_video_cpu"
  input_stream: "VIDEO:input_video_cpu"
  input_stream: "START_POS:box_output"
  output_stream: "VIZ:boxes"

  input_stream_handler {
    input_stream_handler: "SyncSetInputStreamHandler"
    options {
      [mediapipe.SyncSetInputStreamHandlerOptions.ext] {
        sync_set {
          tag_index: "TRACKING"
          tag_index: "TRACK_TIME"
        }
        sync_set {
          tag_index: "START_POS"
        }
      }
    }
  }

  node_options: {
    [type.googleapis.com/mediapipe.BoxTrackerCalculatorOptions]: {
      tracker_options: {
        track_step_options {
          track_object_and_camera: true
          tracking_degrees: TRACKING_DEGREE_OBJECT_PERSPECTIVE
          inlier_spring_force: 0.0
          static_motion_temporal_ratio: 3e-2
        }
      }
      visualize_tracking_data: false
      streaming_track_data_cache_size: 100
    }
  }
}

node: {
  calculator: "ImageFrameToGpuBufferCalculator"
  input_stream: "overlayed_frame"
  output_stream: "output_video"
}
